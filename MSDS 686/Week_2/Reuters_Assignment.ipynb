{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "4FejM0cEQXUP"
      },
      "source": [
        "# Reuters Assignment\n",
        "## Adapted from Deep Learning with Python by Francois Chollet\n",
        "#### Using the IMDB jupyter notebook as an example follow the prompts below to build a neural network to classify Reuters news wires into 46 different categories."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VLYzbicKQXUX"
      },
      "outputs": [],
      "source": [
        "from IPython.core.display import display, HTML\n",
        "display(HTML(\"<style>.container { width:95% !important; }</style>\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aFH2CgDRQXVZ"
      },
      "outputs": [],
      "source": [
        "# Add the necessary libraries and load the data.\n",
        "from keras import backend\n",
        "from keras.datasets import reuters\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "(train_data, train_labels), (test_data, test_labels) = reuters.load_data(num_words = 10000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kckdgba5QXV2"
      },
      "outputs": [],
      "source": [
        "import operator\n",
        "# Print the word index\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "35rwRsIeQXWZ"
      },
      "outputs": [],
      "source": [
        "# Here is the same function we created for vectorizing the IMDB data.\n",
        "def vectorize_sequences(sequences, dimension=10000):\n",
        "    rword_matrix = tf.sparse.SparseTensor(\n",
        "        # The non-zero locations in each row correspond to the word indices that are found in the document\n",
        "        indices=[[row_idx, word_idx] for row_idx, word_indices in enumerate(sequences) for word_idx in set(word_indices)],\n",
        "        # Use \"1\" as the value of each non-zero index (indicating the word is used in the document)\n",
        "        values=[1 for row_idx, word_indices in enumerate(sequences) for word_idx in set(word_indices)],\n",
        "        # The overall tensor shape\n",
        "        dense_shape=[len(sequences), dimension]\n",
        "    )\n",
        "    # Optimize by ordering the non-zero indices in ascending row-major order\n",
        "    word_matrix = tf.sparse.reorder(word_matrix)\n",
        "    return word_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ez2s5K3ZQXW2"
      },
      "outputs": [],
      "source": [
        "# Split the training data into an 80/20 train/validation split, and then vectorize the train/test/validation datasets\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yN3CPRWGQXXG"
      },
      "outputs": [],
      "source": [
        "# Print the unique train labels (there should be 46)\n",
        "# Print the shape of x_train\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZQdFycDNQXXP"
      },
      "outputs": [],
      "source": [
        "# Keras has a built-in function for categorical encoding which we saw in the MNIST workbook\n",
        "from keras.utils.np_utils import to_categorical"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fB6Irop5QXXY"
      },
      "outputs": [],
      "source": [
        "# Convert the labels to categorical\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OP9I_bOUQXXk"
      },
      "outputs": [],
      "source": [
        "# Import models and layers from Keras\n",
        "from keras import models\n",
        "from keras import layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zIXltq67QXXw"
      },
      "outputs": [],
      "source": [
        "# Build a sequential model network with 1 hidden layer. The input and hidden layer must have more hidden units\n",
        "# than the number of classification categories. Things to think about: input and hidden layer activation,\n",
        "# output activation for a multiclass problem, input shape, output units\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NKDPXa4VQXX9"
      },
      "outputs": [],
      "source": [
        "# Compile the model. Think about what optimizer, loss function, and metrics will you use.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bogp4BrGQXYJ"
      },
      "outputs": [],
      "source": [
        "# Train your model on the training data for 20 epochs and 500 batch size and a validation split = 20%.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cFMw_I8FQXYU"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a93HH_RGTlw5"
      },
      "outputs": [],
      "source": [
        "# Use this bit of code to view the History output.\n",
        "hist = pd.DataFrame(history.history)\n",
        "print(hist.tail())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2UC1Wq-0QXYd"
      },
      "outputs": [],
      "source": [
        "# Let's plot the loss and accuracy vs epochs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RtdrPkJBQXYk"
      },
      "outputs": [],
      "source": [
        "# Use the IMDB example to plot the validataion and training loss vs epochs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RBDWbbJUQXYt"
      },
      "outputs": [],
      "source": [
        "# Use the IMDB example to plot the validation and training accuracy vs epochs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sR-uHo3lQXYy"
      },
      "outputs": [],
      "source": [
        "# Evaluate the model on the test data and print the results\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "JPH31AvJtx35"
      },
      "source": [
        "Build a new model and try to get the  accuracy as high as you can. Things to try: more hidden layers and hiddent units, activation types, epochs, batch size, and validation_split. Try as many models as you like.  \n",
        "\n",
        "Be sure to clear the session each time: `backend.clear_session()`. Copy your best model the end of the notebook.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_xy1Q-QwQXZB"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Reuters_Assignment.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
